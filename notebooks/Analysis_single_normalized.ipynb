{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean file with modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from SproutDataset import SproutDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import hdbscan\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from lightly.loss import NTXentLoss\n",
    "\n",
    "import inverse_mapping_functions as imf\n",
    "import Siamese_Architecture as SA\n",
    "\n",
    "import umap.umap_ as umap\n",
    "import tqdm\n",
    "\n",
    "plt.rcParams['image.origin'] = 'lower'\n",
    "\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_none = SproutDataset(dataset_path=\"C:\\\\Users\\\\tania\\\\Documents\\\\SPICE\\\\SPROUTS\\\\spectra_11Feb2023.nc\", augmentation_type=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"C:\\\\Users\\\\tania\\Documents\\CU Boulder\\CU Alpine\\models_ckpts\\single_norm_epoch=14-step=91500.ckpt\"\n",
    "# outputs = SA.run_model(checkpoint, dataset_none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacked_outputs = np.stack(outputs).squeeze()\n",
    "# stacked_outputs.shape \n",
    "# np.save('saved_outputs//stacked_outputs_single64_feb23_normspec.npy', stacked_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_outputs = np.load('saved_outputs//stacked_outputs_single64_feb23_normspec.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test clustering with various parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in tqdm.tqdm([10, 20, 30]):\n",
    "    for y in [2, 5, 10]:\n",
    "        clusterer = hdbscan.HDBSCAN(min_cluster_size=x, min_samples=y, metric='euclidean') #<=> cosine?\n",
    "        clusterer.fit(stacked_outputs)\n",
    "        labels = clusterer.labels_\n",
    "        np.save(f'saved_outputs//clustering//labels_single_normspec_feb23_minclus{x}_minsamp{y}.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "plt.figure(figsize=(15,13))\n",
    "for x in [10, 20, 30]:\n",
    "    for y in [2, 5, 10]:\n",
    "        c+=1\n",
    "        plt.subplot(4,3,c)\n",
    "        labels = np.load(f'saved_outputs//clustering//labels_single_normspec_feb23_minclus{x}_minsamp{y}.npy')\n",
    "        imf.map_clusters(labels, dataset_path=\"C:\\\\Users\\\\tania\\\\Documents\\\\SPICE\\\\SPROUTS\\\\spectra_11Feb2023.nc\", selected_clusters=None)\n",
    "        \n",
    "        plt.title(f\"min_cluster = {x}, min_samples = {y}\")\n",
    "plt.suptitle('norm_15epochs_fullytrained_minclus_single')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot average spectra for a single cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = (30,10)\n",
    "labels = np.load(f'saved_outputs//labels_double_normspec_15epochs_Feb23_minclus{30}_minsamp{10}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_labels = labels.reshape(610, 192)\n",
    "unique_clusters = np.unique(current_labels[~np.isnan(current_labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imf.plot_n_random_spectra_cluster(labels, stacked_outputs, chosen_cluster=1, dataset=dataset_none, nbr_items=len(np.where(labels==1)[0]), plot_on_map=False, log_scale=False,\n",
    "#                                   dataset_path=\"C:\\\\Users\\\\tania\\\\Documents\\\\SPICE\\\\SPROUTS\\\\spectra_11Feb2023.nc\")\n",
    "\n",
    "#for i in unique_clusters:\n",
    "av_spectra = imf.plot_average_spectra_cluster(labels, stacked_outputs, chosen_cluster=2, dataset=dataset_none, log_scale=False,\n",
    "                                  dataset_path=\"C:\\\\Users\\\\tania\\\\Documents\\\\SPICE\\\\SPROUTS\\\\spectra_11Feb2023.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(av_spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inverse_mapping_functions import WAVELENGTHS_ARRAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12,4], tight_layout=True)\n",
    "plt.plot(WAVELENGTHS_ARRAY, np.nanmean(av_spectra, axis=0), label = 'mean spectrum')\n",
    "plt.plot(WAVELENGTHS_ARRAY, np.nanmedian(av_spectra, axis=0), alpha=0.5, label = 'median spectrum')\n",
    "plt.xlabel('Wavelength ($\\AA$)')\n",
    "plt.title('Cluster #2')\n",
    "plt.yscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[12, 4], tight_layout=True)\n",
    "ax.plot(WAVELENGTHS_ARRAY, np.nanmean(av_spectra, axis=0), label='mean spectrum')\n",
    "ax.plot(WAVELENGTHS_ARRAY, np.nanmedian(av_spectra, axis=0), alpha=0.5, label='median spectrum')\n",
    "ax.set_xlabel('Wavelength ($\\AA$)')\n",
    "ax.set_title('Cluster #2')\n",
    "ax.legend()\n",
    "\n",
    "# Add inset (e.g. zoom into 750-850 Ã…)\n",
    "axins = inset_axes(ax, width=\"55%\", height=\"65%\", loc='upper left')\n",
    "axins.plot(WAVELENGTHS_ARRAY, np.nanmean(av_spectra, axis=0))\n",
    "axins.plot(WAVELENGTHS_ARRAY, np.nanmedian(av_spectra, axis=0), alpha=0.5)\n",
    "axins.text(0.05, 0.8, 'Zoom on 700-800 $\\AA$', transform=axins.transAxes, fontsize=15)\n",
    "axins.set_xlim(700, 800)\n",
    "axins.set_ylim(0, 1.2)\n",
    "axins.set_xticks([])\n",
    "axins.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # embedding_L2 = stacked_outputs / np.linalg.norm(stacked_outputs, ord=2)\n",
    "# clusterer = hdbscan.hdbscan_.HDBSCAN(min_cluster_size=10, min_samples=5, cluster_selection_epsilon=.5, metric='euclidean')\n",
    "# clusterer.fit(stacked_outputs)\n",
    "# labels = clusterer.labels_\n",
    "# np.save('saved_outputs//clustered_outputs_double64_minidata_minclus10_minsamp5_eps05.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusterer = hdbscan.hdbscan_.HDBSCAN(min_cluster_size=15, min_samples=5, cluster_selection_epsilon=.5, metric='euclidean')\n",
    "# clusterer.fit(stacked_outputs)\n",
    "# labels = clusterer.labels_\n",
    "# np.save('saved_outputs//clustered_outputs_double64_minidata_minclus15_minsamp5_eps05.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = np.load('saved_outputs\\clustered_outputs_double64_minidata_minclus10_minsamp5_eps05.npy') \n",
    "# imf.map_clusters(labels, selected_clusters = None, dataset_path=\"C:\\\\Users\\\\tania\\\\Documents\\\\SPICE\\\\SPROUTS\\\\spectra_11Feb2023.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(labels, bins=np.arange(-1,np.max(labels)+2)-0.5, density=True, range=(-2,2)), plt.yscale('log');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducer = umap.UMAP(n_neighbors=30, min_dist=0.01, n_components=2, random_state=42)\n",
    "# projected_data = reducer.fit_transform(stacked_outputs)\n",
    "# np.save('saved_outputs//umap_data_64dou_minidataFeb11_neig30_dist001_10_2.npy', projected_data)\n",
    "\n",
    "# # projected_data = np.load('saved_outputs//umap_data_64dou_fulldata_neig15_dist01.npy')\n",
    "# # stacked_outputs = np.load('saved_outputs//stacked_outputs_double64_fulldata.npy')\n",
    "# # labels = np.load('saved_outputs//clustered_outputs_double64_fulldata_minclus30_minsamp30.npy')\n",
    "# projected_data = np.load('saved_outputs//umap_data_64dou_minidataFeb11_neig30_dist001_10_2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.load('saved_outputs\\clustered_outputs_double64_minidata_minclus5_minsamp2_eps05.npy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_clusters = [0]  # List of cluster labels to plot\n",
    "selected_points = projected_data[np.isin(labels, target_clusters)]\n",
    "selected_labels = labels[np.isin(labels, target_clusters)]\n",
    "norm = Normalize(vmin=labels.min(), vmax=labels.max())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(selected_points[:, 0], selected_points[:, 1], c=selected_labels, cmap='tab20', norm=norm, s=3)\n",
    "plt.title(f\"Scatter Plot for Clusters {target_clusters}\\nn_neighbors=15, min_dist=0.1\\nmin_cluster_size=50, min_samples=5\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 14))\n",
    "plt.subplot(211)\n",
    "scatter = plt.scatter(projected_data[:, 0], projected_data[:, 1], c=labels, cmap='tab20', s=1)\n",
    "plt.colorbar()\n",
    "plt.title('UMAP Projection to 2D - double augmentation')\n",
    "plt.xlabel('UMAP Dimension 1')\n",
    "plt.ylabel('UMAP Dimension 2')\n",
    "plt.subplot(212)\n",
    "plt.hist2d(projected_data[:, 0], projected_data[:, 1], bins=200)\n",
    "plt.colorbar()\n",
    "plt.grid(True)\n",
    "plt.title('Density histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels01 = np.load('saved_outputs\\clustered_outputs_double64_minidata_minclus50_minsamp5_eps0point1.npy')\n",
    "labels1 = np.load('saved_outputs\\clustered_outputs_double64_minidata_minclus50_minsamp5_eps1.npy') \n",
    "labels05 = np.load('saved_outputs\\clustered_outputs_double64_minidata_minclus50_minsamp5_eps0point5.npy')\n",
    "labels0 = np.load('saved_outputs\\clustered_outputs_double64_minidata_minclus50_minsamp5_eps0.npy')\n",
    "labels2 = np.load('saved_outputs\\clustered_outputs_double64_minidata_minclus50_minsamp5_eps2.npy')\n",
    "labels10 = np.load('saved_outputs\\clustered_outputs_double64_minidata_minclus50_minsamp5_eps10.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('0.5')\n",
    "imf.map_clusters(labels05, selected_clusters = None, dataset_path=\"C:\\\\Users\\\\tania\\\\Documents\\\\SPICE\\\\SPROUTS\\\\spectra_11Feb2023.nc\")\n",
    "print('0.1')\n",
    "imf.map_clusters(labels01, selected_clusters = None, dataset_path=\"C:\\\\Users\\\\tania\\\\Documents\\\\SPICE\\\\SPROUTS\\\\spectra_11Feb2023.nc\")\n",
    "print('1')\n",
    "imf.map_clusters(labels1, selected_clusters = None, dataset_path=\"C:\\\\Users\\\\tania\\\\Documents\\\\SPICE\\\\SPROUTS\\\\spectra_11Feb2023.nc\")\n",
    "print('0')\n",
    "imf.map_clusters(labels0, selected_clusters = None, dataset_path=\"C:\\\\Users\\\\tania\\\\Documents\\\\SPICE\\\\SPROUTS\\\\spectra_11Feb2023.nc\")\n",
    "print('2')\n",
    "imf.map_clusters(labels2, selected_clusters = None, dataset_path=\"C:\\\\Users\\\\tania\\\\Documents\\\\SPICE\\\\SPROUTS\\\\spectra_11Feb2023.nc\")\n",
    "print('10')\n",
    "imf.map_clusters(labels10, selected_clusters = None, dataset_path=\"C:\\\\Users\\\\tania\\\\Documents\\\\SPICE\\\\SPROUTS\\\\spectra_11Feb2023.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imf.map_item_map(item_nbr=9790, dataset=\"C:\\\\Users\\\\tania\\\\Documents\\\\SPICE\\\\SPROUTS\\\\spectra_11Feb2023.nc\", plot=False, title='2023-02-11 T 15:35:40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

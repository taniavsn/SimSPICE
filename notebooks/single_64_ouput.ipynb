{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean file with modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(parent_dir)\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from simspice.data import SproutDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import hdbscan\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from lightly.loss import NTXentLoss\n",
    "\n",
    "from simspice.utils import inverse_mapping_functions as imf\n",
    "from simspice.models import Siamese_Architecture as SA\n",
    "\n",
    "import umap.umap_ as umap\n",
    "import tqdm\n",
    "plt.rcParams['image.origin'] = 'lower'\n",
    "\n",
    "simspice = 'C:\\\\Users\\\\tania\\\\Documents\\\\CU Boulder\\\\CU Fall 2024\\\\ASEN 6337\\\\Individual project\\\\SimSPICE\\\\'\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_path = \"C:\\\\Users\\\\tania\\\\Documents\\\\SPICE\\\\SPROUTS\\\\spectra_11Feb2023.nc\"\n",
    "dataset_path = \"C:\\\\Users\\\\tania\\\\Documents\\\\SPICE\\\\SPROUTS\\\\datasets_deepL\\\\spectra_Feb2023_short_wvl.nc\"\n",
    "dataset_log = SproutDataset.SproutDataset(dataset_path=dataset_path, augmentation_type='single', log_space=True, normalize_intensity=False)\n",
    "dataset = SproutDataset.SproutDataset(dataset_path=dataset_path, augmentation_type='single', log_space=False, normalize_intensity=False)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "            dataset_log,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(dataset.__getitem__(3075)[0].squeeze())\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(dataset_log.__getitem__(3075)[0].squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue training from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = simspice+\"\\\\notebooks\\\\FullDataset_64_singleAug_normalized_spec\\\\02sqq41e\\\\checkpoints\\\\epoch=4-step=9075.ckpt\"\n",
    "# model = SA.SimSiam.load_from_checkpoint(checkpoint)  # Continue epochs\n",
    "\n",
    "# accelerator = \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "# wandb_logger = WandbLogger(project=\"FullDataset_64_singleAug_normalized_spec\", log_model=True)\n",
    "# trainer = pl.Trainer(max_epochs=10, devices=1, accelerator=accelerator, logger=wandb_logger)\n",
    "# trainer.fit(model=model, train_dataloaders=dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train from zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SA.SimSiam(output_dim=64, backbone_output_dim=128, hidden_layer_dim=128)\n",
    "accelerator = \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "wandb_logger = WandbLogger(project=\"miniDataset_64_singleAug_shortwvl_log\", log_model=True)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=5, devices=1, accelerator=accelerator, logger=wandb_logger)\n",
    "trainer.fit(model=model, train_dataloaders=dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = pl.Trainer(max_epochs=5, devices=1, accelerator=accelerator)#, logger=wandb_logger)\n",
    "# trainer.fit(model=model, train_dataloaders=dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_none = SproutDataset.SproutDataset(dataset_path=\"C:\\\\Users\\\\tania\\\\Documents\\\\SPICE\\\\SPROUTS\\\\datasets_deepL\\\\spectra_Feb2023.nc\", augmentation_type=None)\n",
    "# outputs = SA.run_model(checkpoint, dataset_none)\n",
    "model.eval()\n",
    "outputs = []\n",
    "with torch.no_grad():  # Disable gradient computation for inference\n",
    "    for i in tqdm.tqdm(range (dataset_none.__len__())):\n",
    "        spec = dataset_none.__getitem__(i).unsqueeze(0)\n",
    "        # Move tensor to the same device as the model\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model = model.to(device)\n",
    "        spec = spec.to(device)\n",
    "\n",
    "        outputs.append(model(spec)[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_outputs = np.stack(outputs).squeeze()\n",
    "stacked_outputs.shape\n",
    "np.save(simspice+'jobs\\\\model_outputs\\\\stacked_outputs_single64_feb23_log_15epochs.npy', stacked_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_outputs = np.load(simspice+'jobs\\\\model_outputs\\\\stacked_outputs_single64_feb23_log.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in [10, 20, 30]:\n",
    "# for x in [20, 30]:\n",
    "    for y in tqdm.tqdm([5, 10, 15]):\n",
    "        clusterer = hdbscan.HDBSCAN(min_cluster_size=x, min_samples=y, metric='manhattan') # <=> cosine?\n",
    "        clusterer.fit(stacked_outputs)\n",
    "        labels = clusterer.labels_\n",
    "        np.save(simspice+f'jobs\\\\clustering\\\\log_single_Feb23_15epo_L1_minclus{x}_minsamp{y}.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "plt.figure(figsize=(12,15))\n",
    "for x in [10, 20, 30]:\n",
    "    for y in [5, 10, 15]:\n",
    "        c+=1\n",
    "        plt.subplot(4,3,c)\n",
    "        labels = np.load(simspice+f'jobs\\\\clustering\\\\log_single_Feb23_15epo_L1_minclus{x}_minsamp{y}.npy')\n",
    "        # labels = np.load(f\"C:\\\\Users\\\\tania\\Documents\\\\CU Boulder\\CU Fall 2024\\\\ASEN 6337\\\\Individual project\\\\SPICE_DeepLearning\\saved_outputs_1Apr25\\labels-cos_single64_Feb23_minclus{x}_minsamp{y}.npy\")\n",
    "        imf.map_clusters(labels, dataset_path=\"C:\\\\Users\\\\tania\\\\Documents\\\\SPICE\\\\SPROUTS\\\\datasets_deepL\\\\spectra_Feb2023.nc\", selected_clusters=None)\n",
    "        plt.title(f\"min_cluster = {x}\\nmin_samples = {y}\")\n",
    "plt.suptitle('Feb23_minclus_single_log_15epochs_L1 distance')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP(n_neighbors=50, min_dist=0.1, n_components=2, random_state=42)\n",
    "projected_data = reducer.fit_transform(stacked_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('saved_outputs//umap_data_64sin_fulldata_nei15_dist01_50_5.npy', projected_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projected_data = np.load('saved_outputs//umap_data_64sin_fulldata_nei15_dist01_50_5.npy')\n",
    "# stacked_outputs = np.load('saved_outputs//stacked_outputs_64_fulldata.npy')\n",
    "#labels = np.load('saved_outputs//labels_single64_fulldata_minclus50_minsamp5_unnormalized.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_clusters = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15]  # List of cluster labels to plot\n",
    "selected_points = projected_data[np.isin(labels, target_clusters)]\n",
    "selected_labels = labels[np.isin(labels, target_clusters)]\n",
    "norm = Normalize(vmin=labels.min(), vmax=labels.max())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(selected_points[:, 0], selected_points[:, 1], c=selected_labels, cmap='tab20', norm=norm, s=3)\n",
    "plt.title(f\"Scatter Plot for Clusters {target_clusters} out of [{labels.min()} - {labels.max()}]\\nmin_cluster_size=30, min_samples=5\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 14))\n",
    "plt.subplot(211)\n",
    "scatter = plt.scatter(projected_data[:, 0], projected_data[:, 1], c=labels, cmap='tab20', s=1)\n",
    "plt.colorbar()\n",
    "plt.title('UMAP Projection to 2D')\n",
    "plt.xlabel('UMAP Dimension 1')\n",
    "plt.ylabel('UMAP Dimension 2')\n",
    "plt.subplot(212)\n",
    "plt.hist2d(projected_data[:, 0], projected_data[:, 1], bins=200)\n",
    "plt.colorbar()\n",
    "plt.grid(True)\n",
    "plt.title('Density histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.load('saved_outputs//clustered_outputs_single64_fulldata_minclus50_minsamp5.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imf.map_clusters(labels, dataset_path=\"C:\\\\Users\\\\tania\\\\Documents\\\\SPICE\\\\SPROUTS\\\\spectra_train.nc\", selected_clusters=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imf.map_item_map(item_nbr=9899, dataset=\"C:\\\\Users\\\\tania\\\\Documents\\\\SPICE\\\\SPROUTS\\\\spectra_11Feb2023.nc\", plot=False, title=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imf.plot_n_random_spectra_cluster(labels, stacked_outputs, 1, dataset, nbr_items=3, plot_on_map=True,\n",
    "                                  dataset_path=\"C:\\\\Users\\\\tania\\\\Documents\\\\SPICE\\\\SPROUTS\\\\spectra_train_mini.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

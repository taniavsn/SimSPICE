{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dates so far: \n",
    "* December 2022 20-22 (6 dates) in data_L2\n",
    "* June 2022 8-12 (6 dates) in data_L2\n",
    "* February 2023 10-12 (6 dates) in data_L2\n",
    "* Febuary 2022 20-25 (7 dates) in data_L2\n",
    "* May 2022 1-5 (6 dates) in data_L2\n",
    "\n",
    "Total: 30 dates, so $30\\times610\\times190$ pixels, with 17 spectral lines each "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation: gains (brigher or darker) -- spectral augmentation, shifting (red or blue), adding noise (photon or cosmic rays spikes)\n",
    "\n",
    "Pytorch lightning / Jacks (google)\n",
    "\n",
    "Implement data loader that can return any of the spectra in any of the dates and will return the spectrum augmented (original and a version of the spectrum with random offset and random gain random photon noise and random spikes of GCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import sys\n",
    "from torch import nn\n",
    "# import lightning as L\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import csv\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from brokenaxes import brokenaxes\n",
    "import warnings \n",
    "import tqdm\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simspice.data.SproutDataset import SproutDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from simspice.utils.Augmentation import Augmentation\n",
    "from simspice.data.Sprout_ML import Sprout_ML, interpolate_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "4\n",
      "<torch.cuda.device object at 0x7f457af6da90>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NVIDIA A100 80GB PCIe'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.device(0))\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Test zone\n",
    "----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = 'C:\\\\Users\\\\tania\\\\Documents\\\\SPICE\\\\SPROUTS\\\\data_L2\\\\'  \n",
    "sprout = Sprout_ML(directory_path, 'solo_L2_spice-n-ras_20220220T125345_V22_100663594-000.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wvlarrays = sprout.get_wvl_arrays_A()\n",
    "cubes = sprout.get_cubes()\n",
    "keys = sprout.get_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_arrays_padded, masks = sprout.pad_flux_array(method='zeros')\n",
    "wvl_arrays_padded = sprout.pad_wvl_arrays()\n",
    "print(flux_arrays_padded[0].shape, masks[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[20,4])\n",
    "plt.subplot(1,4,1)\n",
    "plt.plot(wvl_arrays_padded[0], flux_arrays_padded[0][:,300,150]*10, label='spectrum')\n",
    "plt.plot(wvl_arrays_padded[0], masks[0][:,300,150], label='mask')\n",
    "plt.legend()\n",
    "plt.title('O III / Mg IX at one pixel')\n",
    "plt.subplot(1,4,2)\n",
    "plt.plot(wvl_arrays_padded[0], aug.add_photon_noise(flux_arrays_padded[0][:,300,150]*10), label='spectrum')\n",
    "plt.plot(wvl_arrays_padded[0], masks[0][:,300,150], label='mask')\n",
    "plt.legend()\n",
    "plt.title('O III / Mg IX at one pixel, photon noise')\n",
    "plt.subplot(1,4,3)\n",
    "plt.plot(wvl_arrays_padded[0], aug.add_GCR_noise(flux_arrays_padded[0][:,300,150]*10, hit_probability=0.02), label='spectrum')\n",
    "plt.plot(wvl_arrays_padded[0], masks[0][:,300,150], label='mask')\n",
    "plt.legend()\n",
    "plt.title('O III / Mg IX at one pixel, GCR noise')\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "shifted_spectrum = aug.shift_spectrum(wvl_arrays_padded[0], flux_arrays_padded[0][:,300,150]*10, shift=1)  \n",
    "plt.plot(wvl_arrays_padded[0], flux_arrays_padded[0][:,300,150]*10, label=\"Original\")\n",
    "plt.plot(wvl_arrays_padded[0], shifted_spectrum, label=\"Shifted (1 $\\AA$)\", linestyle='--')\n",
    "plt.xlabel(\"Wavelength (nm)\")\n",
    "plt.ylabel(\"Intensity\")\n",
    "plt.legend()\n",
    "plt.title('O III / Mg IX at one pixel, shifted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wvl_all = np.hstack(wvl_arrays_padded)\n",
    "mask_all = np.vstack(masks)\n",
    "cubes_all = np.vstack(flux_arrays_padded)\n",
    "print('Full wavelength array shape: ', wvl_all.shape, '\\nFull spectrum shape : ', cubes_all.shape, '\\nFull mask shape : ', mask_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot mask, full specrta, and noised full spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spectra = xr.open_dataset(\"C:\\\\Users\\\\tania\\\\Documents\\\\SPICE\\\\SPROUTS\\\\spectra_train.nc\")\n",
    "item = all_spectra.isel(index=3075)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = Augmentation(type_distrib_gain='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug.run_all_augmentations(item)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[7,4], tight_layout=True)\n",
    "plt.plot(item['wvl'].values, aug.run_all_augmentations(item)[0], label='spectrum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12,12], tight_layout=True)\n",
    "plt.subplot(4,1,1)\n",
    "plt.plot(item['wvl'].values, item['flux'].values*10, label='spectrum')\n",
    "plt.plot(wvl_all, mask_all[:,300,150], label='mask')\n",
    "plt.legend()\n",
    "plt.title('Full spectrum at one pixel')\n",
    "plt.subplot(4,1,2)\n",
    "plt.plot(item['wvl'], aug.add_photon_noise(item['flux'].values*10), label='spectrum')\n",
    "# plt.plot(wvl_all, masks[0][:,300,150], label='mask')\n",
    "plt.legend()\n",
    "plt.title('Full spectrum at one pixel, photon noise')\n",
    "plt.subplot(4,1,3)\n",
    "plt.plot(item['wvl'], aug.add_GCR_noise(item)*10, label='spectrum')\n",
    "plt.legend()\n",
    "plt.title('Full spectrum at one pixel, GCR noise')\n",
    "\n",
    "plt.subplot(4,1,4)\n",
    "shifted_spectrum = aug.add_shift_spectrum(item)  \n",
    "plt.plot(item['wvl'], item['flux'].values*10, label=\"Original\")\n",
    "plt.plot(item['wvl'], shifted_spectrum[0]*10, label=\"Shifted (1 $\\AA$)\", linestyle='--')\n",
    "plt.xlabel(\"Wavelength (nm)\")\n",
    "plt.ylabel(\"Intensity\")\n",
    "plt.legend()\n",
    "plt.title('Full spectrum at one pixel, shifted')\n",
    "plt.suptitle('Data visualization and augmentation\\n', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------\n",
    "# End of the test zone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write all spectral info in a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_spectra_charac_to_csv(directory, csv_file):\n",
    "\n",
    "    with open(csv_file, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Filename', 'Spectral size 1', 'Spectral size 2', 'Spectral size 3', 'Spectral size 4', 'Spectral size 5', 'Spectral size 6', \n",
    "                            'Spectral size 7', 'Spectral size 8', 'Spectral range 1', 'Spectral range 2', 'Spectral range 3','Spectral range 4', \n",
    "                            'Spectral range 5', 'Spectral range 6', 'Spectral range 7', 'Spectral range 8'])  \n",
    "\n",
    "        for filename in os.listdir(directory):\n",
    "            if os.path.isfile(os.path.join(directory, filename)):\n",
    "                file = Sprout_ML(directory, filename)\n",
    "                rasters = file.get_cubes()     # Get a list of all the rasters\n",
    "                wavelength_arrays = file.get_wvl_arrays_A()\n",
    "                spectral_sizes = []\n",
    "                ranges = []\n",
    "                for r, w in zip(rasters, wavelength_arrays):\n",
    "                    spectral_size = r.shape[0] \n",
    "                    spectral_sizes.append(spectral_size)\n",
    "                    range = (w[0], w[-1])\n",
    "                    ranges.append(f\"{range[0]}-{range[1]}\")\n",
    "                # padding with empty strings if fewer than 8\n",
    "                # spectral_sizes = spectral_sizes[:8] + [''] * (8 - len(spectral_sizes))\n",
    "                \n",
    "                writer.writerow([filename] + spectral_sizes + ranges ) \n",
    "\n",
    "\n",
    "# if __name__ == '__main__': ## Execute when file runs as a script, but not when imported as a module\n",
    "directory_path = 'C:\\\\Users\\\\tania\\\\Documents\\\\SPICE\\\\SPROUTS\\\\data_L2\\\\'  \n",
    "csv_file_path = 'C:\\\\Users\\\\tania\\\\Documents\\\\SPICE\\\\SPROUTS\\\\spectra_dimensions.csv' \n",
    "\n",
    "#write_spectra_charac_to_csv(directory_path, csv_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write all spectra in a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def write_files_to_csv(directory, csv_file):\n",
    "\n",
    "#     with open(csv_file, 'w', newline='') as f:\n",
    "#         writer = csv.writer(f)\n",
    "#         writer.writerow(['index', 'flux', 'mask', 'wvl'])  \n",
    "#         i=0\n",
    "#         for filename in os.listdir(directory):\n",
    "#             if os.path.isfile(os.path.join(directory, filename)):\n",
    "#                 file = Sprout_ML(directory, filename)\n",
    "#                 padded_spectra, masks =  file.pad_flux_array(method='zeros') # get the padded flux arrays and corresponding masks\n",
    "#                 wvl_arrays_padded = file.pad_wvl_arrays() # get the padded wavelengths arrays\n",
    "\n",
    "#                 # transform the list of cubes to a single cube\n",
    "#                 full_spectra = np.vstack(padded_spectra) \n",
    "#                 full_wvl = np.hstack(wvl_arrays_padded)\n",
    "#                 full_mask = np.vstack(masks)\n",
    "#                 for k in range(full_spectra.shape[1]):\n",
    "#                     for l in range(full_spectra.shape[2]):    \n",
    "#                         writer.writerow([str(i)+str(full_spectra[:,k,l])+str(full_wvl)+str(full_mask[:,k,l])]) \n",
    "#                         i+=1\n",
    "\n",
    "# directory_path = '/d0/tvaresano/SimSPICE/\\\\data_L2\\\\'  \n",
    "# csv_file_path = 'C:\\\\Users\\\\tania\\\\Documents\\\\SPICE\\\\SPROUTS\\\\spectra_train.csv' \n",
    "\n",
    "# #write_files_to_csv(directory_path, csv_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to netcdf format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [03:18<00:00, 19.89s/it]\n"
     ]
    }
   ],
   "source": [
    "def write_files_to_netcdf(directory, netcdf_file, nbr_files=None):\n",
    "    all_flux = []\n",
    "    all_mask = []\n",
    "    all_k = []\n",
    "    all_l = []\n",
    "    index = []\n",
    "    filenames = []\n",
    "    \n",
    "    i = 0\n",
    "    for filename in tqdm.tqdm(os.listdir(directory)[:nbr_files]):\n",
    "        if os.path.isfile(os.path.join(directory, filename)):\n",
    "            file = Sprout_ML(directory, filename)\n",
    "            wvl_common = file.common_wvl\n",
    "            \n",
    "            #################################\n",
    "            padded_spectra, masks = file.pad_flux_array(method='zeros')  # get padded flux arrays and masks\n",
    "            wvl_arrays_padded = file.pad_wvl_arrays()\n",
    "            full_spectra = np.vstack(padded_spectra)  # combine spectra into a single array\n",
    "            full_mask = np.vstack(masks)  # combine masks\n",
    "            full_wvl = np.hstack(wvl_arrays_padded)\n",
    "\n",
    "            for k in range(full_spectra.shape[1]):\n",
    "                for l in range(full_spectra.shape[2]):\n",
    "                    spec_common_wvl, mask_common_wvl = interpolate_arrays(wvl_common, full_wvl, full_spectra[:, k, l], full_mask[:, k, l])\n",
    "                    all_flux.append(spec_common_wvl)\n",
    "                    all_mask.append(mask_common_wvl)\n",
    "                    all_k.append(k)\n",
    "                    all_l.append(l)\n",
    "                    index.append(i)\n",
    "                    filenames.append(filename)\n",
    "                    i += 1\n",
    "\n",
    "    # xarray Dataset\n",
    "    ds = xr.Dataset(\n",
    "        {\n",
    "            \"flux\": ((\"index\", \"wvl\"), np.array(all_flux)),\n",
    "            \"mask\": ((\"index\", \"wvl\"), np.array(all_mask)),\n",
    "            \"x-index\" : ((\"index\"), all_k),\n",
    "            \"y-index\" : ((\"index\"), all_l),\n",
    "            \"filename\" : ((\"index\"), filenames),\n",
    "        },\n",
    "        coords={\"index\": index,\n",
    "                \"wvl\" : wvl_common, # interp1d array set of wvl every single spectrum is going to be interpolated into.\n",
    "                }\n",
    "            )\n",
    "\n",
    "    # Save to NetCDF\n",
    "    ds.to_netcdf(netcdf_file)\n",
    "\n",
    "directory_path = '/d0/tvaresano/SimSPICE/data_L2/'\n",
    "netcdf_file_path = '/d0/tvaresano/SimSPICE/spectra_train.nc'\n",
    "\n",
    "write_files_to_netcdf(directory_path, netcdf_file_path, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netcdf_file_path = 'C:\\\\Users\\\\tania\\\\Documents\\\\SPICE\\\\SPROUTS\\\\datasets_deepL\\\\spectra_Feb2023.nc'\n",
    "directory_path = 'C:\\\\Users\\\\tania\\\\Documents\\\\SPICE\\\\SPROUTS\\\\data_L2\\\\Feb2023\\\\'\n",
    "write_files_to_netcdf(directory_path, netcdf_file_path, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self supervised: Backbone + fine tuning\n",
    "\n",
    "* `Dataset` stores the samples and their corresponding labels. Custom Dataset class must implement three functions: `__init__`, `__len__`, and `__getitem__`\n",
    "* `DataLoader` wraps iterable around Dataset to enable easy access to samples\n",
    "\n",
    "* `__getitem__` function loads and returns a sample from the dataset at the given index idx. Based on the index, it identifies the image’s location on disk, converts that to a tensor using read_image, retrieves the corresponding label from the csv data in self.img_labels, calls the transform functions on them (if applicable), and returns the tensor image and corresponding label in a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SproutDataset(augmentation_type=None)\n",
    "item = dataset.__getitem__(75)\n",
    "## or item = dataset(75)\n",
    "# print(dataset.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = dataset.all_spectra.isel(index=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = Augmentation(type_distrib_gain='unirform')\n",
    "res_all = aug.run_all_augmentations(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    item_nbr = random.randint(0, len(dataset))\n",
    "    item = dataset.__getitem__(item_nbr)\n",
    "    res_all = aug.run_all_augmentations(item)\n",
    "    res_all1 = aug.run_all_augmentations(item)\n",
    "    res_all2 = aug.run_all_augmentations(item)\n",
    "    \n",
    "    # Define the x-axis ranges to keep\n",
    "    x1_start, x1_end = 690, 800\n",
    "    x2_start, x2_end = 950, max(item['wvl'].values)+10\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(20, 5), gridspec_kw={'width_ratios': [1, 1]})\n",
    "    fig.subplots_adjust(wspace=0.05)\n",
    "    \n",
    "    # Plot data on the first axis\n",
    "    ax1.plot(item['wvl'].values, res_all[0], label='augmented', color='plum')\n",
    "    ax1.plot(item['wvl'].values, res_all[1], label='augmented mask', color='plum', linestyle='--')\n",
    "    # ax1.plot(item['wvl'].values, res_all1[0], label='augmented1')\n",
    "    # ax1.plot(item['wvl'].values, res_all2[0], label='augmented2')\n",
    "    ax1.plot(item['wvl'].values, item['flux'].values, label='original', color='k')\n",
    "    ax1.plot(item['wvl'].values, item['mask'].values, label='original mask', color='k', linestyle='--')\n",
    "    ax1.set_xlim(x1_start, x1_end)\n",
    "    ax1.set_ylim(0,15)\n",
    "    #ax1.set_yscale('log')\n",
    "    \n",
    "    # Plot data on the second axis\n",
    "    ax2.plot(item['wvl'].values, res_all[0], label='augmented', color='plum')\n",
    "    ax2.plot(item['wvl'].values, res_all[1], label='augmented mask', color='plum', linestyle='--')\n",
    "    # ax2.plot(item['wvl'].values, res_all1[0], label='augmented1')\n",
    "    # ax2.plot(item['wvl'].values, res_all2[0], label='augmented2')\n",
    "    ax2.plot(item['wvl'].values, item['flux'].values, label='original', color='k')\n",
    "    ax2.plot(item['wvl'].values, item['mask'].values, label='original mask', color='k', linestyle='--')\n",
    "    ax2.set_xlim(x2_start, x2_end)\n",
    "    ax2.set_ylim(0,15)\n",
    "    #ax2.set_yscale('log')\n",
    "    \n",
    "    # Hide the broken x-axis ticks between plots\n",
    "    ax1.spines['right'].set_visible(False)\n",
    "    ax2.spines['left'].set_visible(False)\n",
    "    ax1.yaxis.tick_left()\n",
    "    ax2.yaxis.tick_right()\n",
    "    ax2.tick_params(labelleft=False)\n",
    "    \n",
    "    # Add diagonal lines to indicate the axis break\n",
    "    d = .015\n",
    "    kwargs = dict(transform=ax1.transAxes, color='k', clip_on=False)\n",
    "    ax1.plot((1 - d, 1 + d), (-d, +d), **kwargs)\n",
    "    ax1.plot((1 - d, 1 + d), (1 - d, 1 + d), **kwargs)\n",
    "\n",
    "    kwargs.update(transform=ax2.transAxes)\n",
    "    ax2.plot((-d, +d), (-d, +d), **kwargs)\n",
    "    ax2.plot((-d, +d), (1 - d, 1 + d), **kwargs)\n",
    "    \n",
    "    plt.legend()\n",
    "    fig.suptitle(f'Augmentations for item # {item_nbr}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "dataset = SproutDataset()\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call lighlty (but assumes an image but we have 1D signals)\n",
    "# Check what architectures are popular for 1D data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create / request academic account of weights and biases wandb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simspice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
